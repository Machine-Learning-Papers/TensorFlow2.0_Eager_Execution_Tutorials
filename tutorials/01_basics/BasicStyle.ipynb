{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicStyle.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellocybernetics/TensorFlow2.0_Eager_Execution_Tutorials/blob/master/tutorials/01_basics/BasicStyle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2wXVpo2lhf2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f53997e0-5ebd-417f-8a81-da3657a5780f"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade tf-nightly-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 96.1MB 175kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 358kB 20.4MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 11.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S3kHX4Vqhl5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdgYCKIShn9M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make DataSet"
      ]
    },
    {
      "metadata": {
        "id": "lcVt1_Zth3_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "If you have numpy data, you can use\n",
        "tensor_data = tf.convert_to_tensor(numpy_data, dtype=tf.float32)\n",
        "for translation into tf.Tensor.\n",
        "'''\n",
        "# example training data\n",
        "feature = tf.random.normal(shape=[50000, 1000])\n",
        "target = tf.random.normal(shape=[50000, 10])\n",
        "\n",
        "# example validation data\n",
        "val_feature = tf.random.normal(shape=[10000, 1000])\n",
        "val_target = tf.random.normal(shape=[10000, 10])\n",
        "\n",
        "# example test data\n",
        "test_feature = tf.random.normal(shape=[5000, 1000])\n",
        "test_target = tf.random.normal(shape=[5000, 10])\n",
        "\n",
        "\n",
        "# make dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((feature, target))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_feature, val_target))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_feature, test_target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFAMHrm7SL5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "071d0426-317b-49d0-ffcd-6ec59a91c07a"
      },
      "cell_type": "code",
      "source": [
        "# A dataset have shape information except batchsize and data type.\n",
        "dataset"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((1000,), (10,)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "s5wtoZOsSzft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training data should be shuffled every epoch.\n",
        "# 10000 is buffer size.\n",
        "dataset = dataset.shuffle(10000)\n",
        "\n",
        "# For mini-batch training.\n",
        "# 256 is batch size.\n",
        "dataset = dataset.batch(256)\n",
        "\n",
        "# Of course we can write same code as follows\n",
        "# dataset = dataset.shuffle(10000).batch(256)\n",
        "\n",
        "# validation data and test data do NOT need shuffle.\n",
        "# batch size is as big as possible.\n",
        "val_dataset = val_dataset.batch(10000)\n",
        "test_dataset = test_dataset.batch(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X3JLZxT0UsnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fbf1cfd8-1347-4372-a3f2-bb15db0e434d"
      },
      "cell_type": "code",
      "source": [
        "# dataset is set for batch training.\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 1000), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "6vL6rFO6VFBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make Network"
      ]
    },
    {
      "metadata": {
        "id": "wBzNdkCyiFGs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyNet(tf.keras.Model):\n",
        "    '''\n",
        "    We use basically tf.keras.Model for making network.\n",
        "    This class will manage layers and that's trainable parameters.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        \n",
        "        \n",
        "        # We can use tf.keras.Sequential \n",
        "        # which has a role of putting together some layers.\n",
        "        # This class inherits tf.keras.Model, so this can manege parameters too.\n",
        "        # This class only receive layers.Layer class.\n",
        "        # (Note that tf.keras.Sequential receive tf.keras.layers.ReLU())\n",
        "       \n",
        "        self.layer1 = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(1024),\n",
        "            tf.keras.layers.ReLU(),\n",
        "            tf.keras.layers.BatchNormalization(axis=-1),\n",
        "            tf.keras.layers.Dropout(rate=0.2),\n",
        "        ])\n",
        "        \n",
        "        # Of course we can write some layers separately.\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(256)\n",
        "        self.bn = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "        self.do = tf.keras.layers.Dropout(rate=0.2)\n",
        "        \n",
        "        self.dense_output = tf.keras.layers.Dense(10)\n",
        "    \n",
        "    # tf.function is jit compiler which translate python code into TF graph.\n",
        "    @tf.function\n",
        "    def call(self, x, training=False):\n",
        "        # tf.keras.Sequential class have training propaty\n",
        "        # which manege behavior of dropout and batchnormalization etc.\n",
        "        h = self.layer1(x, training=training)\n",
        "        \n",
        "        h = self.dense(h)\n",
        "        # we can use tf.nn.relu function instead of tf.keras.layers.ReLU()\n",
        "        h = tf.nn.relu(h)\n",
        "\n",
        "        # BatchNormalization and Dropout class also have training property.\n",
        "        h = self.bn(h, training=training)\n",
        "        h = self.do(h, training=training)\n",
        "        \n",
        "        return self.dense_output(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60kaVa6BiJzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTEFbRxqizpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "a784eb57-7caf-4333-c869-b20958f32606"
      },
      "cell_type": "code",
      "source": [
        "# test execution.\n",
        "model(tf.random.normal(shape=[1, 1000]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=1160, shape=(1, 10), dtype=float32, numpy=\n",
              "array([[-0.34420356, -1.2885818 ,  0.1190961 , -0.99393785,  0.15190971,\n",
              "         0.09836806,  0.10659645, -1.4151433 ,  0.02022073, -1.2858809 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "mjM1vGKSj5Ri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "50f551b4-c586-48eb-94ca-f1640b88dc92"
      },
      "cell_type": "code",
      "source": [
        "# We can check model compose with model.summary() after first execution.\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_net_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_2 (Sequential)    multiple                  1029120   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch multiple                  1024      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  2570      \n",
            "=================================================================\n",
            "Total params: 1,295,114\n",
            "Trainable params: 1,292,554\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xySVCRU9j7l2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training by hand"
      ]
    },
    {
      "metadata": {
        "id": "1eQ8DRWTbFjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "loss_fn = tf.losses.MeanSquaredError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHTjWBcVbvo6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(feature, target):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(feature, training=True)\n",
        "        loss = loss_fn(target, y_pred)\n",
        "    \n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.variables))\n",
        "    \n",
        "    return loss\n",
        "\n",
        "@tf.function\n",
        "def val_step(feature, target):\n",
        "    \n",
        "    y_pred = model(feature)\n",
        "    loss = loss_fn(target, y_pred)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vzeQsq7DdRmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "39c7e56c-8dda-41de-9e66-b2022bd50310"
      },
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    \n",
        "    running_loss = 0\n",
        "    running_val_loss = 0\n",
        "    \n",
        "    for i, (batch_feature, batch_target) in enumerate(dataset):\n",
        "        loss_ = train_step(batch_feature, batch_target)\n",
        "        running_loss += loss_\n",
        "        \n",
        "    for j, (batch_feature, batch_target) in enumerate(val_dataset):\n",
        "        loss_ = val_step(batch_feature, batch_target)\n",
        "        running_val_loss += loss_\n",
        "        \n",
        "    print(\"----------epoch {}--------\".format(i+1))\n",
        "    print(\"loss: {},  val_loss: {}\".format(running_loss/(i+1), \n",
        "                                           running_val_loss/(j+1)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0407 11:15:35.531675 140100668761984 optimizer_v2.py:961] Gradients does not exist for variables ['sequential_2/batch_normalization_4/moving_mean:0', 'sequential_2/batch_normalization_4/moving_variance:0', 'batch_normalization_5/moving_mean:0', 'batch_normalization_5/moving_variance:0'] when minimizing the loss.\n",
            "W0407 11:15:35.860958 140100668761984 optimizer_v2.py:961] Gradients does not exist for variables ['sequential_2/batch_normalization_4/moving_mean:0', 'sequential_2/batch_normalization_4/moving_variance:0', 'batch_normalization_5/moving_mean:0', 'batch_normalization_5/moving_variance:0'] when minimizing the loss.\n",
            "W0407 11:15:44.869919 140100668761984 optimizer_v2.py:961] Gradients does not exist for variables ['sequential_2/batch_normalization_4/moving_mean:0', 'sequential_2/batch_normalization_4/moving_variance:0', 'batch_normalization_5/moving_mean:0', 'batch_normalization_5/moving_variance:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------epoch 196--------\n",
            "loss: 0.7635518908500671,  val_loss: 1.0994179248809814\n",
            "----------epoch 196--------\n",
            "loss: 0.7118832468986511,  val_loss: 1.120743989944458\n",
            "----------epoch 196--------\n",
            "loss: 0.6699531078338623,  val_loss: 1.143028974533081\n",
            "----------epoch 196--------\n",
            "loss: 0.6334821581840515,  val_loss: 1.15768301486969\n",
            "----------epoch 196--------\n",
            "loss: 0.6007084250450134,  val_loss: 1.1724363565444946\n",
            "----------epoch 196--------\n",
            "loss: 0.5760673880577087,  val_loss: 1.1808465719223022\n",
            "----------epoch 196--------\n",
            "loss: 0.5515231490135193,  val_loss: 1.1818556785583496\n",
            "----------epoch 196--------\n",
            "loss: 0.5310335159301758,  val_loss: 1.189349889755249\n",
            "----------epoch 196--------\n",
            "loss: 0.5123671293258667,  val_loss: 1.1940315961837769\n",
            "----------epoch 196--------\n",
            "loss: 0.49744296073913574,  val_loss: 1.1978554725646973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "74I_3WOkejci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}