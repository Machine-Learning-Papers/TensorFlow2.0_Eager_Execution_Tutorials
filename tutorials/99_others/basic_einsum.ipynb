{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_einsum.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellocybernetics/TensorFlow2.0_Eager_Execution_Tutorials/blob/master/tutorials/99_others/basic_einsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UnJjDwFaR2e1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "756a2932-b1af-469f-bdad-f5a0b21e55c6"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade tf-nightly-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 86.5MB 286kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 8.0MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 358kB 10.0MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.4MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OuY5ERIeR8ni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKpbACrFSAj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### scalar * scalar\n",
        "$$\n",
        "y = ax\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "NW8FYRTaSMGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06a5e641-fd87-48ef-c573-62a82afdb0e7"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.0)\n",
        "a = tf.constant(2.0)\n",
        "\n",
        "y = tf.einsum(\",->\", a, x)\n",
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=20, shape=(), dtype=float32, numpy=2.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "U_aPSL4kSUxi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### scalar * vector\n",
        "\n",
        "$$\n",
        "{\\bf y} = a {\\bf x}\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[i] = a x[i]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "q1ED2tp0SsKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bbd4a1e-83ef-4fd8-ea10-448efaac21e9"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1.0, 2.0])\n",
        "a = tf.constant(1.0)\n",
        "\n",
        "y = tf.einsum(\",i->i\", a, x)\n",
        "y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=32, shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "mVoMgW1pS3A5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### vector * vector with dot product\n",
        "\n",
        "$$\n",
        "y =\\bf a^T x\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y = \\sum_i a[i]x[i]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "7JRRoPJGTduP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "665f0f87-b196-4614-853c-9886db66abc9"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1.0, 2.0, 3.0])\n",
        "a = tf.constant([1.0, 1.0, 1.0])\n",
        "\n",
        "y = tf.einsum(\"i,i->\", a, x)\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=48, shape=(), dtype=float32, numpy=6.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "0cLk4QK-TsnP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### vector * vector with hadamard product\n",
        "\n",
        "$$\n",
        "\\bf y = a \\odot x\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[i] = a[i]x[i]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "sarpABDCUTXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2edb79e-09e6-409b-8213-493fdf05a7c6"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1.0, 2.0, 3.0])\n",
        "a = tf.constant([1.0, 1.0, 1.0])\n",
        "\n",
        "y = tf.einsum(\"i,i->i\", a, x)\n",
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=58, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "s2qulkrvUWte",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### vector * vector with direct product\n",
        "\n",
        "$$\n",
        "\\bf y = a \\otimes x\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[i, j] = a[i]x[j]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "K8u2veAgU9Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4d08203b-73aa-43ed-9e77-6b08afc901e7"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1.0, 2.0, 3.0])\n",
        "a = tf.constant([1.0, 1.0, 1.0])\n",
        "\n",
        "y = tf.einsum(\"i,j->ij\", a, x)\n",
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=72, shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [1., 2., 3.],\n",
              "       [1., 2., 3.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "sEp8w_--VAeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### scalar * matrix\n",
        "\n",
        "\n",
        "$$\n",
        "{\\bf Y} = a {\\bf X}\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[i, j] = ax[i, j]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "35WpzuF7VX0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0631e13a-9424-4276-9900-4cc14fb449a2"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1.0, 2.0, 3.0],\n",
        "                 [4.0, 5.0, 6.0],\n",
        "                 [7.0, 8.0, 9.0]])\n",
        "a = tf.constant(2.0)\n",
        "\n",
        "y = tf.einsum(\",ij->ij\", a, x)\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=86, shape=(3, 3), dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.],\n",
              "       [14., 16., 18.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "j8S5lYZWVkwF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### vector * matrix\n",
        "\n",
        "$$\n",
        "{\\bf y} = \\bf a^T X\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[j] = \\sum_i a[i]x[i, j]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "B5xfJ3IQWC5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a66cde6a-5cf2-4709-d39d-c3967056f2a2"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1.0, 2.0, 3.0],\n",
        "                 [4.0, 5.0, 6.0],\n",
        "                 [7.0, 8.0, 9.0]])\n",
        "a = tf.constant([2.0, 2.0, 2.0])\n",
        "\n",
        "\n",
        "y = tf.einsum(\"i,ij->j\", a, x)\n",
        "y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=100, shape=(3,), dtype=float32, numpy=array([24., 30., 36.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "U8FDy2vLWJf0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### matrix * vector\n",
        "\n",
        "$$\n",
        "{\\bf y} = \\bf A x\n",
        "$$\n",
        "\n",
        "This calculation is represented with Ingredient indication as below.\n",
        "\n",
        "$$\n",
        "y[i] = \\sum_j a[i,j]x[ j]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "3qbyrDExWgRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ea327ad-1b03-49c0-bcc2-d7be54bf657c"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1.0, 2.0, 3.0])\n",
        "a = tf.constant([[2.0, 2.0, 2.0],\n",
        "                 [2.0, 2.0, 2.0],\n",
        "                 [2.0, 2.0, 2.0]])\n",
        "\n",
        "y = tf.einsum(\"ij,j->i\", a, x)\n",
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=114, shape=(3,), dtype=float32, numpy=array([12., 12., 12.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0a1rbcihWs1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Einstein summation convention\n",
        "No need to worry about the order of multiplication  when using ingredient indication because of just dealing with scalars. The above caluclation, \n",
        "\n",
        "$$\n",
        "\\bf y = Ax\n",
        "$$\n",
        "\n",
        "is represented by another ingredient indication.\n",
        "\n",
        "$$\n",
        "y[i] = \\sum_j x[ j]a[i, j]\n",
        "$$\n",
        "\n",
        "And we understand below is same caluclation.\n",
        "\n",
        "$$\n",
        "y[k] = \\sum_i x[i]a[k, i]\n",
        "$$\n",
        "\n",
        "You only have to worry about which axis you want to take the sum. In addition, we do NOT care of using which alphabet for a index. If we see below caluclation without $\\sum$ , \n",
        "\n",
        "$$\n",
        "y[i] = x[ j]a[i, j]\n",
        "$$\n",
        "\n",
        "don't we understand this mean? The index $j$ disappears on the left side, so we regard the index $j$  as used for $\\sum_j$. However if we see below caluclation,\n",
        "\n",
        "$$\n",
        " ... + x[ j]a[i, j] + z[k]b[k,i] + ...\n",
        "$$\n",
        "\n",
        "how do we understand this? If this equation is very very long,  we must be able to imagine calculations from this partial formulas. In this case (No, actually in all cases!) focus on the index that appears in common in one term. The $x[j]a[i,j]$ term have common index$j$. So the index is for $\\sum$. The $z[k]a[k,i]$ term have common index$k$. So the index is for $\\sum$. \n",
        "\n",
        "This rule is called \"Einstein summation convention\"."
      ]
    },
    {
      "metadata": {
        "id": "Pmv-RxtEXwpv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### matrix * matrix\n",
        "\n",
        "$$\n",
        "\\bf Y = AX\n",
        "$$\n",
        "\n",
        "This is represented with Einstein summation convention.\n",
        "\n",
        "$$\n",
        "Y[i, k] = A[i,j]X[j,k]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "R7ikK4NgW9Rf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "51dc9f8f-e44d-444f-ba4d-bd89e6be14ac"
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1.0, 2.0, 3.0],\n",
        "                 [4.0, 5.0, 6.0],\n",
        "                 [7.0, 8.0, 9.0]])\n",
        "a = tf.constant([[1.0, 1.0, 1.0],\n",
        "                 [1.0, 1.0, 1.0],\n",
        "                 [1.0, 1.0, 1.0]])\n",
        "\n",
        "\n",
        "y = tf.einsum(\"ij,jk->ik\", a, x)\n",
        "y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=134, shape=(3, 3), dtype=float32, numpy=\n",
              "array([[12., 15., 18.],\n",
              "       [12., 15., 18.],\n",
              "       [12., 15., 18.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "0_zeP2bSfy40",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Batch matmul\n",
        "A batch data is ${\\bf X} \\in \\mathcal R^{N\\times D}$. A weight matrix is ${\\bf W}\\in \\mathcal R^{D\\times M}$. A bias vector is ${\\bf b} \\in \\mathcal R^{M}$. Batch matmul is \n",
        "\n",
        "$$\n",
        "\\bf Y = XW + 1_Nb^T\n",
        "$$\n",
        "\n",
        "where $\\bf 1_N$ is a $N$-dim vector of all components $1$, so ${\\bf 1_N b^T} \\in R^{N\\times M}$.\n",
        "\n",
        "In Einstein summation convention.\n",
        "\n",
        "$$\n",
        "Y[n, m] = X[n,d]W[d,m] + 1[n]b[m]\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "Wg7Sny4uhJIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "50030fa7-726b-4eb1-8a76-cb1236da2335"
      },
      "cell_type": "code",
      "source": [
        "X = tf.constant([[1.0, 2.0, 3.0],\n",
        "                 [4.0, 5.0, 6.0],\n",
        "                 [7.0, 8.0, 9.0],\n",
        "                 [-7.0, -8.0, -9.0],\n",
        "                 [-4.0, -5.0, -6.0]])\n",
        "W = tf.constant([[1.0, 2.0],\n",
        "                 [-1.0, -1.0],\n",
        "                 [3.0, 2.0]])\n",
        "\n",
        "b = tf.constant([3., -1])\n",
        "ones = tf.ones(shape=[5])\n",
        "\n",
        "y = tf.einsum(\"nd,dm->nm\", X, W) + tf.einsum(\"n,m->nm\", ones, b)\n",
        "y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=306, shape=(5, 2), dtype=float32, numpy=\n",
              "array([[ 11.,   5.],\n",
              "       [ 20.,  14.],\n",
              "       [ 29.,  23.],\n",
              "       [-23., -25.],\n",
              "       [-14., -16.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "EjEcmrWTjZv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow have a function of broadcast, so we don't need to discribe bias vector $\\bf b$ into $\\bf 1_Nb$ "
      ]
    },
    {
      "metadata": {
        "id": "SqEHO0C6i3R_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "155edc25-cb11-4658-e88f-99e85885cb3c"
      },
      "cell_type": "code",
      "source": [
        "y = tf.einsum(\"nd,dm->nm\", X, W) + b\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=324, shape=(5, 2), dtype=float32, numpy=\n",
              "array([[ 11.,   5.],\n",
              "       [ 20.,  14.],\n",
              "       [ 29.,  23.],\n",
              "       [-23., -25.],\n",
              "       [-14., -16.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "z69PBXzcjWBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}